{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9562dcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting neo4j~=5.28.0\n",
      "  Downloading neo4j-5.28.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: pytz in c:\\program files\\python312\\lib\\site-packages (from neo4j~=5.28.0) (2025.2)\n",
      "Downloading neo4j-5.28.2-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: neo4j\n",
      "  Attempting uninstall: neo4j\n",
      "    Found existing installation: neo4j 6.0.3\n",
      "    Uninstalling neo4j-6.0.3:\n",
      "      Successfully uninstalled neo4j-6.0.3\n",
      "Successfully installed neo4j-5.28.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install neo4j~=5.28.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ffaf2f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32e9c578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting odfpy\n",
      "  Downloading odfpy-1.4.1.tar.gz (717 kB)\n",
      "     ---------------------------------------- 0.0/717.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/717.0 kB ? eta -:--:--\n",
      "     -------------- ------------------------- 262.1/717.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 717.0/717.0 kB 3.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: defusedxml in c:\\program files\\python312\\lib\\site-packages (from odfpy) (0.7.1)\n",
      "Building wheels for collected packages: odfpy\n",
      "  Building wheel for odfpy (pyproject.toml): started\n",
      "  Building wheel for odfpy (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for odfpy: filename=odfpy-1.4.1-py2.py3-none-any.whl size=137565 sha256=38e54ab21b04c7a8968cace366fb2349c1bbbaa036c92ea18d73442cfd1d52a2\n",
      "  Stored in directory: c:\\users\\genaiblrancusr66\\appdata\\local\\pip\\cache\\wheels\\36\\5d\\63\\8243a7ee78fff0f944d638fd0e66d7278888f5e2285d7346b6\n",
      "Successfully built odfpy\n",
      "Installing collected packages: odfpy\n",
      "Successfully installed odfpy-1.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install odfpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6114abde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting Grant Knowledge Graph Pipeline\n",
      "============================================================\n",
      "\n",
      "Original columns: ['grantid', 'grantname', 'fundingtype', 'maximumprojectvalueinr', 'maxgrantsubsidy', 'targetverticals', 'keytechnicalfocus', 'SME Size Eligibility', 'Must-Have Criterion 1', 'Must-Have Criterion 2', 'Additional Geographic Filter', 'Country']\n",
      "Cleaned columns: ['grantid', 'grantname', 'fundingtype', 'maximumprojectvalueinr', 'maxgrantsubsidy', 'targetverticals', 'keytechnicalfocus', 'SMESizeEligibility', 'Must-HaveCriterion1', 'Must-HaveCriterion2', 'AdditionalGeographicFilter', 'Country']\n",
      "\n",
      "Sample verticals: [['Manufacturing', 'Service'], ['Manufacturing (High-Energy Clusters)'], ['All Verticals (Commercial/Industrial)']]\n",
      "Sample tech_focus: [['All Green Technologies (EE', 'RE', 'WtE', 'Green Building)'], ['Energy Efficiency (EE) Upgrades (e.g.', 'Motors', 'VFDs)'], ['Rooftop Solar PV ($\\\\le$ 500 kWp)']]\n",
      "Sample country: [['India'], ['India'], ['India']]\n",
      "\n",
      "Processed 11 grant records\n",
      "\n",
      "Sample record:\n",
      "  ID: GIFT-001\n",
      "  Name: MSE-GIFT (Interest Subvention)\n",
      "  Country: ['India']\n",
      "Connected to Neo4j successfully.\n",
      "Clearing existing graph data...\n",
      "\n",
      "============================================================\n",
      "✅ Graph Creation Complete\n",
      "============================================================\n",
      "Nodes Created: 73\n",
      "Relationships Created: 100\n",
      "Properties Set: 158\n",
      "============================================================\n",
      "\n",
      "Verifying graph structure...\n",
      "\n",
      "Graph Statistics:\n",
      "  Grants........................ 11\n",
      "  Verticals..................... 12\n",
      "  Technologies.................. 22\n",
      "  Sizes......................... 3\n",
      "  Criteria...................... 19\n",
      "  Regions....................... 5\n",
      "  Countries..................... 1\n",
      "  Vertical Relationships........ 16\n",
      "  Tech Relationships............ 23\n",
      "  Size Relationships............ 23\n",
      "  Criterion Relationships....... 22\n",
      "  Geographic Relationships...... 5\n",
      "  Country Relationships......... 11\n",
      "\n",
      "Neo4j connection closed.\n",
      "\n",
      "============================================================\n",
      "Pipeline completed successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import os \n",
    "import re\n",
    "\n",
    "# ====================================================================\n",
    "# 1. CONFIGURATION\n",
    "# ====================================================================\n",
    "URI = \"bolt://localhost:7687\"\n",
    "USER = \"neo4j\"\n",
    "PASSWORD = \"KushalKuldipSuhas\" \n",
    "GRANT_EXCEL_PATH = \"grants.xlsx\" \n",
    "\n",
    "# ====================================================================\n",
    "# 2. DATA PREPROCESSING FUNCTION \n",
    "# ====================================================================\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads data from Excel, cleans, and prepares for Neo4j insertion.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Excel file not found at: {file_path}\")\n",
    "    \n",
    "    # Load Excel file\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    print(f\"Original columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Clean column names - remove spaces, special chars, lowercase\n",
    "    # This ensures 'Country' becomes 'Country' (or 'country' if you lowercased it, but here it preserves case)\n",
    "    df.columns = [re.sub(r'\\s+', '', str(col).strip()) for col in df.columns]\n",
    "    \n",
    "    print(f\"Cleaned columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Column mapping based on your actual Excel structure\n",
    "    # Added 'Country' mapping here\n",
    "    COLUMN_MAP = {\n",
    "        'grantid': 'id',\n",
    "        'grantname': 'name',\n",
    "        'fundingtype': 'funding_type', \n",
    "        'maximumprojectvalueinr': 'max_value',\n",
    "        'maxgrantsubsidy': 'max_subsidy',\n",
    "        'targetverticals': 'verticals_raw',\n",
    "        'keytechnicalfocus': 'tech_focus_raw',\n",
    "        'SMESizeEligibility': 'size_eligibility_raw',\n",
    "        'Must-HaveCriterion1': 'criterion_1',\n",
    "        'Must-HaveCriterion2': 'criterion_2',\n",
    "        'AdditionalGeographicFilter': 'geo_filter_raw',\n",
    "        'Country': 'country_raw',  # <--- NEW MAPPING\n",
    "    }\n",
    "    \n",
    "    # Rename columns\n",
    "    df = df.rename(columns=COLUMN_MAP)\n",
    "    \n",
    "    # Add ID column if not present (using row index)\n",
    "    if 'id' not in df.columns:\n",
    "        df['id'] = ['GRANT_' + str(i+1).zfill(3) for i in range(len(df))]\n",
    "    \n",
    "    # Function to clean and split multi-value fields\n",
    "    def clean_and_split(value):\n",
    "        \"\"\"Split comma/semicolon separated values, handle N/A and empty values\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return []\n",
    "        \n",
    "        value_str = str(value).strip()\n",
    "        \n",
    "        # Handle special cases\n",
    "        if value_str.lower() in ['n/a', 'none', '']:\n",
    "            return []\n",
    "        \n",
    "        # Split by comma or semicolon\n",
    "        items = re.split(r'[,;]', value_str)\n",
    "        \n",
    "        # Clean each item\n",
    "        cleaned = []\n",
    "        for item in items:\n",
    "            item = item.strip()\n",
    "            if item and item.lower() not in ['n/a', 'none', '']:\n",
    "                cleaned.append(item)\n",
    "        \n",
    "        return cleaned\n",
    "    \n",
    "    # Process relationship fields\n",
    "    df['verticals'] = df.get('verticals_raw', pd.Series(dtype=object)).apply(clean_and_split)\n",
    "    df['tech_focus'] = df.get('tech_focus_raw', pd.Series(dtype=object)).apply(clean_and_split)\n",
    "    df['size_eligibility'] = df.get('size_eligibility_raw', pd.Series(dtype=object)).apply(clean_and_split)\n",
    "    df['geo_filter'] = df.get('geo_filter_raw', pd.Series(dtype=object)).apply(clean_and_split)\n",
    "    \n",
    "    # Process the new Country field (treated as list to handle multiple countries if needed)\n",
    "    df['country'] = df.get('country_raw', pd.Series(dtype=object)).apply(clean_and_split) # <--- NEW PROCESSING\n",
    "    \n",
    "    # Debug: Show what we're getting\n",
    "    print(f\"\\nSample verticals: {df['verticals'].head(3).tolist()}\")\n",
    "    print(f\"Sample tech_focus: {df['tech_focus'].head(3).tolist()}\")\n",
    "    print(f\"Sample country: {df['country'].head(3).tolist()}\") # <--- NEW DEBUG PRINT\n",
    "    \n",
    "    # Process scalar fields - convert NaN to None\n",
    "    for col in ['name', 'funding_type', 'max_value', 'max_subsidy', 'criterion_1', 'criterion_2']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda x: None if pd.isna(x) else str(x).strip())\n",
    "    \n",
    "    # Select final columns\n",
    "    # Added 'country' to final columns\n",
    "    final_columns = ['id', 'name', 'funding_type', 'max_value', 'max_subsidy', \n",
    "                     'verticals', 'tech_focus', 'size_eligibility', 'geo_filter',\n",
    "                     'criterion_1', 'criterion_2', 'country']\n",
    "    \n",
    "    # Only keep columns that exist\n",
    "    available_columns = [col for col in final_columns if col in df.columns]\n",
    "    processed_data = df[available_columns].to_dict('records')\n",
    "    \n",
    "    # Final type validation\n",
    "    for record in processed_data:\n",
    "        # Ensure lists are lists (Added 'country' here)\n",
    "        for key in ['verticals', 'tech_focus', 'size_eligibility', 'geo_filter', 'country']:\n",
    "            if key not in record:\n",
    "                record[key] = []\n",
    "            elif not isinstance(record[key], list):\n",
    "                record[key] = []\n",
    "        \n",
    "        # Ensure strings are strings or None\n",
    "        for key in ['name', 'funding_type', 'max_value', 'max_subsidy', 'criterion_1', 'criterion_2']:\n",
    "            if key not in record:\n",
    "                record[key] = None\n",
    "            elif pd.isna(record.get(key)):\n",
    "                record[key] = None\n",
    "    \n",
    "    print(f\"\\nProcessed {len(processed_data)} grant records\")\n",
    "    if processed_data:\n",
    "        print(f\"\\nSample record:\")\n",
    "        sample = processed_data[0]\n",
    "        print(f\"  ID: {sample.get('id')}\")\n",
    "        print(f\"  Name: {sample.get('name')}\")\n",
    "        print(f\"  Country: {sample.get('country')}\") # <--- NEW PRINT\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# ====================================================================\n",
    "# 3. NEO4J GRAPH CREATION FUNCTION\n",
    "# ====================================================================\n",
    "\n",
    "def create_knowledge_graph(uri, user, password, data):\n",
    "    \"\"\"\n",
    "    Creates a knowledge graph in Neo4j with proper hierarchical relationships.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"No data to process. Exiting graph creation.\")\n",
    "        return\n",
    "\n",
    "    driver = None\n",
    "    try:\n",
    "        driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        print(\"Connected to Neo4j successfully.\")\n",
    "\n",
    "        # Clear existing data\n",
    "        with driver.session() as session:\n",
    "            print(\"Clearing existing graph data...\")\n",
    "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "        cypher_query = \"\"\"\n",
    "        UNWIND $grant_list AS g\n",
    "        \n",
    "        // 1. Create/Update Grant Node\n",
    "        MERGE (grant:Grant {id: g.id})\n",
    "        SET grant.name = g.name,\n",
    "            grant.funding_type = g.funding_type,\n",
    "            grant.max_value = g.max_value,\n",
    "            grant.max_subsidy = g.max_subsidy\n",
    "        \n",
    "        // 2. Verticals\n",
    "        FOREACH (vertical_name IN [v IN g.verticals WHERE v IS NOT NULL AND TRIM(v) <> ''] |\n",
    "            MERGE (vert:Vertical {name: TRIM(vertical_name)})\n",
    "            MERGE (grant)-[:TARGETS_VERTICAL]->(vert)\n",
    "        )\n",
    "        \n",
    "        // 3. Technologies\n",
    "        FOREACH (tech_name IN [t IN g.tech_focus WHERE t IS NOT NULL AND TRIM(t) <> ''] |\n",
    "            MERGE (tech:Technology {name: TRIM(tech_name)})\n",
    "            MERGE (grant)-[:USES_TECH]->(tech)\n",
    "        )\n",
    "        \n",
    "        // 4. SME Size Eligibility\n",
    "        FOREACH (size_name IN [s IN g.size_eligibility WHERE s IS NOT NULL AND TRIM(s) <> ''] |\n",
    "            MERGE (sz:Size {name: TRIM(size_name)})\n",
    "            MERGE (grant)-[:ELIGIBLE_FOR_SIZE]->(sz)\n",
    "        )\n",
    "        \n",
    "        // 5. Criterion 1\n",
    "        FOREACH (c1_desc IN CASE WHEN g.criterion_1 IS NOT NULL AND TRIM(g.criterion_1) <> '' \n",
    "                                  THEN [g.criterion_1] ELSE [] END |\n",
    "            MERGE (c1:Criterion {description: TRIM(c1_desc)})\n",
    "            ON CREATE SET c1.type = 'Must-Have 1'\n",
    "            MERGE (grant)-[:REQUIRES_CRITERION {type: 'Must-Have 1'}]->(c1)\n",
    "        )\n",
    "        \n",
    "        // 6. Criterion 2\n",
    "        FOREACH (c2_desc IN CASE WHEN g.criterion_2 IS NOT NULL AND TRIM(g.criterion_2) <> '' \n",
    "                                  THEN [g.criterion_2] ELSE [] END |\n",
    "            MERGE (c2:Criterion {description: TRIM(c2_desc)})\n",
    "            ON CREATE SET c2.type = 'Must-Have 2'\n",
    "            MERGE (grant)-[:REQUIRES_CRITERION {type: 'Must-Have 2'}]->(c2)\n",
    "        )\n",
    "        \n",
    "        // 7. Geographic Filters\n",
    "        FOREACH (region_name IN [r IN g.geo_filter WHERE r IS NOT NULL AND TRIM(r) <> ''] |\n",
    "            MERGE (reg:Region {name: TRIM(region_name)})\n",
    "            MERGE (grant)-[:HAS_GEOGRAPHIC_FILTER]->(reg)\n",
    "        )\n",
    "        \n",
    "        // 8. Country (NEW SECTION)\n",
    "        FOREACH (country_name IN [c IN g.country WHERE c IS NOT NULL AND TRIM(c) <> ''] |\n",
    "            MERGE (cntry:Country {name: TRIM(country_name)})\n",
    "            MERGE (grant)-[:APPLICABLE_TO_COUNTRY]->(cntry)\n",
    "        )\n",
    "        \n",
    "        RETURN count(DISTINCT grant) AS processedGrants\n",
    "        \"\"\"\n",
    "\n",
    "        with driver.session() as session:\n",
    "            result = session.run(cypher_query, grant_list=data)\n",
    "            summary = result.consume()\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"✅ Graph Creation Complete\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"Nodes Created: {summary.counters.nodes_created}\")\n",
    "            print(f\"Relationships Created: {summary.counters.relationships_created}\")\n",
    "            print(f\"Properties Set: {summary.counters.properties_set}\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            # Verify the graph\n",
    "            print(\"\\nVerifying graph structure...\")\n",
    "            verify_query = \"\"\"\n",
    "            MATCH (g:Grant)\n",
    "            RETURN 'Grants' as entity, count(g) as count\n",
    "            UNION ALL\n",
    "            MATCH (v:Vertical)\n",
    "            RETURN 'Verticals' as entity, count(v) as count\n",
    "            UNION ALL\n",
    "            MATCH (t:Technology)\n",
    "            RETURN 'Technologies' as entity, count(t) as count\n",
    "            UNION ALL\n",
    "            MATCH (s:Size)\n",
    "            RETURN 'Sizes' as entity, count(s) as count\n",
    "            UNION ALL\n",
    "            MATCH (c:Criterion)\n",
    "            RETURN 'Criteria' as entity, count(c) as count\n",
    "            UNION ALL\n",
    "            MATCH (r:Region)\n",
    "            RETURN 'Regions' as entity, count(r) as count\n",
    "            UNION ALL\n",
    "            MATCH (cntry:Country)\n",
    "            RETURN 'Countries' as entity, count(cntry) as count\n",
    "            UNION ALL\n",
    "            MATCH ()-[r:APPLICABLE_TO_COUNTRY]->()\n",
    "            RETURN 'Country Relationships' as entity, count(r) as count\n",
    "            \"\"\"\n",
    "            \n",
    "            # Added Verification for other existing relationships (condensed previous verify query for brevity in display)\n",
    "            # You can keep the full original verification query and just append the Country parts\n",
    "            \n",
    "            full_verify_query = \"\"\"\n",
    "            MATCH (g:Grant) RETURN 'Grants' as entity, count(g) as count\n",
    "            UNION ALL MATCH (v:Vertical) RETURN 'Verticals' as entity, count(v) as count\n",
    "            UNION ALL MATCH (t:Technology) RETURN 'Technologies' as entity, count(t) as count\n",
    "            UNION ALL MATCH (s:Size) RETURN 'Sizes' as entity, count(s) as count\n",
    "            UNION ALL MATCH (c:Criterion) RETURN 'Criteria' as entity, count(c) as count\n",
    "            UNION ALL MATCH (r:Region) RETURN 'Regions' as entity, count(r) as count\n",
    "            UNION ALL MATCH (cntry:Country) RETURN 'Countries' as entity, count(cntry) as count\n",
    "            UNION ALL MATCH ()-[r:TARGETS_VERTICAL]->() RETURN 'Vertical Relationships' as entity, count(r) as count\n",
    "            UNION ALL MATCH ()-[r:USES_TECH]->() RETURN 'Tech Relationships' as entity, count(r) as count\n",
    "            UNION ALL MATCH ()-[r:ELIGIBLE_FOR_SIZE]->() RETURN 'Size Relationships' as entity, count(r) as count\n",
    "            UNION ALL MATCH ()-[r:REQUIRES_CRITERION]->() RETURN 'Criterion Relationships' as entity, count(r) as count\n",
    "            UNION ALL MATCH ()-[r:HAS_GEOGRAPHIC_FILTER]->() RETURN 'Geographic Relationships' as entity, count(r) as count\n",
    "            UNION ALL MATCH ()-[r:APPLICABLE_TO_COUNTRY]->() RETURN 'Country Relationships' as entity, count(r) as count\n",
    "            \"\"\"\n",
    "\n",
    "            verification = session.run(full_verify_query)\n",
    "            print(\"\\nGraph Statistics:\")\n",
    "            for record in verification:\n",
    "                print(f\"  {record['entity']:.<30} {record['count']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ ERROR during graph creation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.close()\n",
    "            print(\"\\nNeo4j connection closed.\")\n",
    "\n",
    "# ====================================================================\n",
    "# 4. EXECUTION\n",
    "# ====================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"=\"*60)\n",
    "        print(\"Starting Grant Knowledge Graph Pipeline\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        # 1. Load and preprocess the data\n",
    "        grant_records = load_and_preprocess_data(GRANT_EXCEL_PATH)\n",
    "        \n",
    "        # 2. Create the graph in Neo4j\n",
    "        create_knowledge_graph(URI, USER, PASSWORD, grant_records)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Pipeline completed successfully!\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n❌ ERROR: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ An unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc9f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
